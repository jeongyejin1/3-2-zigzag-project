import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
# ìë°” ì„¤ì¹˜ í•„ìš” ì—†ëŠ” Kiwi ë¶„ì„ê¸° ì‚¬ìš©
from kiwipiepy import Kiwi
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation
import re

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# 1. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
file_path = 'zigzag_total_dataset_labeled.xlsx'
try:
    df = pd.read_excel(file_path)
    print(">> ë°ì´í„° ë¡œë“œ ì„±ê³µ!")
except FileNotFoundError:
    print("âŒ ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# ì‡¼í•‘ëª° ë§¤í•‘
mall_mapping = {
    'ìŠ¬ë¡œìš°ì•¤ë“œ': ['127356723', '135006673', '119829258'],
    'ê³ ê³ ì‹±': ['140751630', '134111551', '123099184'],
    'ë¸”ë™ì—…': ['100119896', '127456743', '129133636'],
    'ìœ¡ìœ¡ê±¸ì¦ˆ': ['100408842', '100511186', '120497545', '105657134'],
    'ë² ë‹ˆí† ': ['101062215', '133185968', '111411935', '100424661'],
    'ë² ì´ë¸ë¦¬': ['134770445', '150922802', '135012008'],
    'ì–´í…€': ['131059251', '137691186', '108222216'],
    'í•«í•‘': ['131967482', '147654541', '103347769']
}

# ID ì¶”ì¶œ ë° ë§¤í•‘
if 'url' in df.columns:
    df['product_id'] = df['url'].str.split('/').str[-1].astype(str)
id_to_mall = {str(pid): mall for mall, ids in mall_mapping.items() for pid in ids}
df['shopping_mall'] = df['product_id'].map(id_to_mall)
df = df.dropna(subset=['shopping_mall'])

# ---------------------------------------------------------
# 2. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ê°•ë ¥í•œ ë¶ˆìš©ì–´ ì²˜ë¦¬)
# ---------------------------------------------------------
kiwi = Kiwi()

# [í•µì‹¬] ë¶„ì„ì— ë°©í•´ë˜ëŠ” ë‹¨ì–´ë“¤ì„ ì—¬ê¸°ì— ë‹¤ ë„£ì–´ì£¼ì„¸ìš”!
stop_words = [
    'ì§„ì§œ', 'ë„ˆë¬´', 'ì •ë§', 'ì™„ì „', 'ê·¸ëƒ¥', 'ì •ë„', 'ìƒê°', 'êµ¬ë§¤', 'ì£¼ë¬¸', 'ë°°ì†¡',
    'ë¶€ë¶„', 'ì‚´ì§', 'ì¡°ê¸ˆ', 'ë§ˆìŒ', 'ë³´ê³ ', 'ëŠë‚Œ', 'ê³„ì†', 'ë‹¤ë¥¸', 'ì—­ì‹œ', 'ì œì¼',
    'ì‚¬ì§„', 'í™”ë©´', 'ëª¨ë¸', 'í›„ê¸°', 'ë¦¬ë·°', 'ì‚¬ëŒ', 'ë•Œë¬¸', 'ì´ë²ˆ', 'ê³ ë¯¼', 'ë§Œì¡±',
    'ë„ì°©', 'í•˜ë£¨', 'ì´ì•Œ', 'ê¸°ì‚¬', 'í¬ì¥', 'ìƒíƒœ'  # ë°°ì†¡ ê´€ë ¨ ë‹¨ì–´ë„ ê¸ì • í† í”½ì—ì„œ ì œì™¸í•˜ê³  ì‹¶ìœ¼ë©´ ì¶”ê°€
]


def preprocess(text):
    text = re.sub(r'[^ê°€-í£\s]', '', str(text))
    tokens = kiwi.tokenize(text)
    # ì¼ë°˜ ëª…ì‚¬(NNG), ê³ ìœ  ëª…ì‚¬(NNP)ë§Œ ì¶”ì¶œ
    nouns = [t.form for t in tokens if t.tag in ['NNG', 'NNP']]
    return [n for n in nouns if len(n) > 1 and n not in stop_words]


print(">> í˜•íƒœì†Œ ë¶„ì„ ë° ë¶ˆìš©ì–´ ì œê±° ì¤‘... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)")
df['processed_tokens'] = df['ë¦¬ë·°'].apply(preprocess)
print(">> ì „ì²˜ë¦¬ ì™„ë£Œ! ê¹”ë”í•œ ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n")


# ---------------------------------------------------------
# 3. ê°„ê²°í•œ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± í•¨ìˆ˜
# ---------------------------------------------------------
def run_topic_modeling_clean(tokens_list, title, color_map):
    if len(tokens_list) < 10: return

    dummy = lambda x: x
    vectorizer = CountVectorizer(tokenizer=dummy, preprocessor=dummy, min_df=3)
    dtm = vectorizer.fit_transform(tokens_list)

    # í† í”½ 1ê°œë¡œ í•µì‹¬ë§Œ ì¶”ì¶œ
    lda = LatentDirichletAllocation(n_components=1, random_state=42)
    lda.fit(dtm)

    feature_names = vectorizer.get_feature_names_out()
    topic_dist = lda.components_[0]
    word_dict = dict(zip(feature_names, topic_dist))

    # [í•µì‹¬] ìƒìœ„ 10ê°œ ë‹¨ì–´ë§Œ ì¶”ì¶œí•˜ì—¬ ì›Œë“œí´ë¼ìš°ë“œì— ì „ë‹¬
    sorted_words = sorted(word_dict.items(), key=lambda x: x[1], reverse=True)[:10]
    top_word_dict = dict(sorted_words)
    top_keywords = ", ".join([w[0] for w in sorted_words[:5]])  # ì œëª©ìš© 5ê°œ

    # max_words=20ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ìµœëŒ€ 20ê°œê¹Œì§€ë§Œ ê·¸ë¦¬ë„ë¡ ì œí•œ
    wc = WordCloud(font_path='malgun.ttf', background_color='white',
                   width=600, height=400, colormap=color_map,
                   max_words=20)
    wc.generate_from_frequencies(top_word_dict)

    plt.figure(figsize=(6, 4))  # ê·¸ë¦¼ í¬ê¸°ë„ ì•„ë‹´í•˜ê²Œ
    plt.imshow(wc, interpolation="bilinear")
    plt.axis("off")
    plt.title(f"{title}\n(í•µì‹¬: {top_keywords})", fontsize=12)

    filename = "clean_" + title.replace(" ", "_").replace("(", "").replace(")", "") + ".png"
    plt.savefig(filename, bbox_inches='tight')  # ì—¬ë°± ì—†ì´ ê¹”ë”í•˜ê²Œ ì €ì¥
    plt.close()
    print(f"   ğŸ“„ ì €ì¥ ì™„ë£Œ: {filename} -> í•µì‹¬: [{top_keywords}]")


# ---------------------------------------------------------
# 4. ì‹¤í–‰ ë£¨í”„
# ---------------------------------------------------------
mall_list = list(mall_mapping.keys())

for mall in mall_list:
    print(f"\nğŸ” Analyzing... [{mall}]")
    mall_data = df[df['shopping_mall'] == mall]

    pos_tokens = mall_data[mall_data['label'] == 1]['processed_tokens']
    run_topic_modeling_clean(pos_tokens, f"{mall} (ê¸ì •)", "viridis")  # ê¹”ë”í•œ íŒŒë€ìƒ‰ ê³„ì—´

    neg_tokens = mall_data[mall_data['label'] == 0]['processed_tokens']
    if len(neg_tokens) > 5:
        run_topic_modeling_clean(neg_tokens, f"{mall} (ë¶€ì •)", "inferno")  # ë¶‰ì€ìƒ‰ ê³„ì—´
    else:
        print(f"   Skip: {mall}ì€ ë¶€ì • ë¦¬ë·°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤.")

print("\nâœ… ëª¨ë“  ë¶„ì„ì´ ëë‚¬ìŠµë‹ˆë‹¤! 'clean_'ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” íŒŒì¼ë“¤ì„ í™•ì¸í•˜ì„¸ìš”.")